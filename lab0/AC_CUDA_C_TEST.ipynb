{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1>Accelerating Applications with CUDA C/C++ (Pre-lab)</h1></div>\n",
    "<div align=\"right\">Test Jupyter and CUDA</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CUDA](./images/CUDA_Logo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Accelerated Systems\n",
    "\n",
    "*Accelerated systems*, also referred to as *heterogeneous systems*, are those composed of both CPUs and GPUs. Accelerated systems run CPU programs which in turn, launch functions that will benefit from the massive parallelism provided by GPUs. This lab environment is an accelerated system which includes an NVIDIA GPU. Information about this GPU can be queried with the `nvidia-smi` (*Systems Management Interface*) command line command. Issue the `nvidia-smi` command now, by `CTRL` + `ENTER` on the code execution cell below. You will find these cells throughout this lab any time you need to execute code. The output from running the command will be printed just below the code execution cell after the code runs. After running the code execution block immediately below, take care to find and note the name of the GPU in the output.\n",
    "\n",
    "\n",
    "\n",
    "#### NOTE:\n",
    "    * Under Linux  Nvidia-SMI command is typically located in /usr/bin\n",
    "    * Under Windows-10 it is stored by default in the following location:\n",
    "    C:\\Windows\\System32\\DriverStore\\FileRepository\\nvdm*\\nvidia-smi.exe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise: Test a Hello GPU Kernel\n",
    "\n",
    "In the line BELOW change sm_61 to the correct value depending upon your GPU\n",
    "\n",
    "\n",
    "Maxwell cards (CUDA 6 until CUDA 11)\n",
    "\n",
    "    SM50 or SM_50, compute_50 –\n",
    "    Tesla/Quadro M series.\n",
    "    Deprecated from CUDA 11, will be dropped in future versions.\n",
    "    SM52 or SM_52, compute_52 –\n",
    "    Quadro M6000 , GeForce 900, GTX-970, GTX-980, GTX Titan X.\n",
    "    SM53 or SM_53, compute_53 –\n",
    "    Tegra (Jetson) TX1 / Tegra X1, Drive CX, Drive PX, Jetson Nano.\n",
    "\n",
    "Pascal (CUDA 8 and later)\n",
    "\n",
    "    SM60 or SM_60, compute_60 –\n",
    "    Quadro GP100, Tesla P100, DGX-1 (Generic Pascal)\n",
    "    SM61 or SM_61, compute_61–\n",
    "    GTX 1080, GTX 1070, GTX 1060, GTX 1050, GTX 1030, Titan Xp, Tesla P40, Tesla P4, Discrete GPU on the NVIDIA Drive PX2\n",
    "    SM62 or SM_62, compute_62 – \n",
    "    Integrated GPU on the NVIDIA Drive PX2, Tegra (Jetson) TX2 \n",
    "    \n",
    " Volta (CUDA 9 and later)\n",
    "\n",
    "    SM70 or SM_70, compute_70 –\n",
    "    DGX-1 with Volta, Tesla V100, GTX 1180 (GV104), Titan V, Quadro GV100\n",
    "    SM72 or SM_72, compute_72 –\n",
    "    Jetson AGX Xavier, Drive AGX Pegasus, Xavier NX    \n",
    "\n",
    "Turing (CUDA 10 and later)\n",
    "\n",
    "    SM75 or SM_75, compute_75 –\n",
    "    GTX/RTX Turing – GTX 1660 Ti, RTX 2060, RTX 2070, RTX 2080, Titan RTX, Quadro RTX 4000, Quadro RTX 5000, Quadro RTX 6000, Quadro RTX 8000, Quadro T1000/T2000, Tesla T4 \n",
    "    \n",
    "Ampere (CUDA 11 and later)\n",
    "\n",
    "    SM80 or SM_80, compute_80 –\n",
    "    Tesla A100 (GA100), NVIDIA DGX-A100, RTX Ampere – RTX 3080     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc -arch=sm_61 -o hello-gpu 01-hello-gpu-solution.cu -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the NVIDIA profiler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvprof ./hello-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setting Up the NVIDIA Visual Profiler\n",
    "\n",
    "Open a terminal session and type \"nvvp\" to start the NVIDIA profiler. It is a graphical application (using Ecclipse) so it needs to run on your graphical desktop rather than in a browser (well there is a way but we won't bother).\n",
    "\n",
    "Choose workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
